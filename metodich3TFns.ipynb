{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Gr6WSWZeif"
   },
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 3. TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bue68reXZeig"
   },
   "source": [
    "## Содержание методического пособия:\n",
    "\n",
    "\n",
    "<ol>\n",
    "<li>Что такое TensorFlow</li>\n",
    "<li>Основы синтаксиса TensorFlow</li>\n",
    "<li>Пример нейросети на TensorFlow</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dnPeuVjZeih"
   },
   "source": [
    "## Что такое TensorFlow\n",
    "\n",
    "TensorFlow - это фреймворк для создания ML моделей. TensorFlow предназначен в первую очередь для Deep Learning, т.е. создания современных нейросетей. Однако в TensorFlow также есть поддержка некоторых классических ML алгоритмов: K-means clustering, Random Forests, Support Vector Machines, Gaussian Mixture Model clustering, Linear/logistic regression.\n",
    "\n",
    "TensorFlow выпустила компания Google в 2015. TensorFlow - это opensource проект. На данный момент это один из основных инструментов для создания нейросетей в рабочих целях. TensorFlow позволяет создавать нейронные сети как для кластеров из большого количества вычислительных устройств, так и для устройств с относительно небольшой вычислитей мощностью, таких как смартфоны и одноплатные компьютеры.\n",
    "\n",
    "TensorFlow применяется самой компанией Google для ее поиска, почты, переводчика, распознования голоса, внутренних нужд наподобие мониторинга оборудования. TensorFlow используется различными компаниями для различных проектов связанных с компьютерным зрением, решением задач ранжирования и т.д.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv0alDOPZeih"
   },
   "source": [
    "## Основы синтаксиса TensorFlow\n",
    "\n",
    "Процесс создания нейросети на TensorFlow схож с разобранным нами процессом обучения нейросети на Keras. Отличее здесь в том, что здесь нам нужно прописать больше деталей в коде. \n",
    "\n",
    "Название TensorFlow означает поток тензоров. Тензоры - это массивы. Данные в компьютере предствлены часто в виде массивах и работа с этими массивами подразумевает их преобразования. Преобразования осуществляются через, к примеру, математические операции. Работа TensorFlow складывается из цепочки преобразований тензоров, т.е. данных. Сами операции осуществляющие преобразование данных представлены в TensorFlow в виде графов. Особенностью TensorFlow версии 1 является то, что сначала необходимо декларировать переменные и вычисления, которые будут совершенны над ними, а потом уже непосредственно запускать работу над данными. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o84IqNt0Zeii"
   },
   "source": [
    "Давайте рассмотрим базовые вещи в синтаксисе Tensorflow 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v4BEDMfZeij"
   },
   "source": [
    "Выведем строку Hello world, а также версию tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfJ55tRrZeik"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "msg = tf.constant('TensorFlow 2.0 Hello World')\n",
    "tf.print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1thj13PZeio"
   },
   "source": [
    "Пример создания тензора - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81yegHijZeio"
   },
   "outputs": [],
   "source": [
    "A = tf.constant([[3, 2], \n",
    "                 [5, 2]])\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlmd9aOnZeir"
   },
   "source": [
    "Приме сложения тензеров - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmdznieKZeis"
   },
   "outputs": [],
   "source": [
    "B = tf.constant([[9, 5], \n",
    "                 [1, 3]])\n",
    "\n",
    "AB = tf.concat(values=[A, B], axis=1)\n",
    "print(AB.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86_adPP6Zeiu"
   },
   "source": [
    "Пример изменения размерности тензора - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvzZxX4MZeiv"
   },
   "outputs": [],
   "source": [
    "tensor = tf.constant([[3, 2], \n",
    "                      [5, 2], \n",
    "                      [9, 5], \n",
    "                      [1, 3]])\n",
    "\n",
    "resh_tensor = tf.reshape(tensor = tensor, shape = [1, 8]) \n",
    "\n",
    "print(f'BEFORE {tensor.numpy()}')\n",
    "print(f'AFTER {resh_tensor.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCrf6xL5Zeiy"
   },
   "source": [
    "Пример умножения матриц, одной из самых частых операций в машинном обучении - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKkt1GPQZeiy"
   },
   "outputs": [],
   "source": [
    "A = tf.constant([[3, 7], \n",
    "                 [1, 9]])\n",
    "\n",
    "\n",
    "B = tf.constant([[10, 10],\n",
    "                 [1000, 1000]])\n",
    "\n",
    "AB = tf.multiply(A, B)\n",
    "print(AB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unatvMYgZei3"
   },
   "source": [
    "Функции tensorflow призваны ускорить вычисления, давайте посмотрим на следующий пример - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Классификация изображений одежды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "Давайте разберем использование tensorflow 2 на примере датасета с одеждой. В это датасете будут находиться маленькие изображения на белом фоне, такие как кросовки, футболки и прочее.\n",
    "\n",
    "В данном случае мы будем использовать High API от TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Импортируем Fashion MNIST датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "Мы будет использовать следующий датасет -  [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) Этот датасет содержит 70,000 черно-белых изображений в 10 категориях. Изображения имеют разрешение 28x28 пикселей.\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "Долгое время в машинном обучение для программ Hello world использовался датасет MNIST с рукописными цифрами. Данный датасет призван несколько усложнить задачу распознования но также подходит в качестве программы Hello world.\n",
    "\n",
    "В этом датасете 60 000 тренировочных изображений и 10 000 тестовых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9FDsUlxCaWW"
   },
   "source": [
    "Датасет содержит следующие классы:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Каждому классу обозначенному цифрой мы можем присвоить текстовое значение -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## Анализ датасета \n",
    "\n",
    "Давайте посмотрим структуры полученного массива данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zW5k_xz1CaWX"
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRFYHB2mCaWb"
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKnCTHz4CaWg"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMPI88iZpO2T"
   },
   "source": [
    "Проанализируем тестовую выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KFnYlcwCaWl"
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJmPr5-ACaWn"
   },
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## Preprocess the data\n",
    "\n",
    "Давайте взглянем на конкретный пример изображений с помощью matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4VEw8Ud9Quh"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz7l27Lz9S1P"
   },
   "source": [
    "Для процесса обучения нейронной сети нам важно перевести данные из диапазона от 0 до 255 в диапазон от 0 до 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bW5WzIPlCaWv"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "Посмотрим первые 25 изображений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTImqg_CaW1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Построение модели\n",
    "\n",
    "Построение нейронной сети подразумевает конфигурацию ее слоев и последующую компиляцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxg1XGm0eOBy"
   },
   "source": [
    "### Определение слоев\n",
    "\n",
    "Давайте создадим 3 слоя нейронной сети с помощью функционала Keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "Первый слой, `tf.keras.layers.Flatten`, трасформирует двумерный массив на входе в одномерный массив.\n",
    "\n",
    "Получившиеся 784(28 x 28) входных нейрона присоединяем к полносвязному слою из 128 нейронов , которые будут использовать функцию активации relu. В выходном слое будет 10 нейронов, по числу классов, которые он должен предсказывать. В нем будет использоваться функция активации softmax и он будет давать предсказание от 0 до 1, где 1 это стопроцентная вероятность.\n",
    "\n",
    "### Компиляция модели\n",
    "\n",
    "Давайте вспомним ключевые понятия, которые нам понадобяться при компиляции:\n",
    "\n",
    "* *Loss function* — меряет как точно работает нейросеть.\n",
    "* *Optimizer* — определяет способ корректировки весов.\n",
    "* *Metrics* — определяет за какие характеристики будут отражаться в процессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## Тренировка модели\n",
    "\n",
    "Здесь все стандартно - данные передаются в нейросеть и сопоставляются изображения и лейблы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4P4zIV7E28Z"
   },
   "source": [
    "### Передача данных в модель\n",
    "\n",
    "Команда непосредственно запускающая процесс обучения называется - `model.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvwvpA64CaW_"
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lZfHNYrZejq"
   },
   "source": [
    "В выводе выше мы следим за точностью в процессе обучения, проверяем точность на тестовых даыннх и меняем параметры нейросети если точность на тестовых данных нас не устраивает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PyD1SYE28q"
   },
   "source": [
    "### Предсказания нейросети\n",
    "\n",
    "Команды ниже позволяют проверить работу натренированной ранее нейросети - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnfNA0CrQLSD"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DmJEUinCaXK"
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsqenuPnCaXO"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sd7Pgsu6CaXP"
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh9yABaME29S"
   },
   "source": [
    "### Проверка предсказаний\n",
    "\n",
    "Matplotlib нам дает возможность посмотреть наше предсказание графически:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko-uzOufSCSe"
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "Давайте сделаем еще несколько предсказаний - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R32zteKHCaXT"
   },
   "source": [
    "## Использование полученной модели\n",
    "\n",
    "Давайте возьмем одно изображение из тестовой выборке и посмотрим предсказание нейронной сети - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRJ7JU7JCaXT"
   },
   "outputs": [],
   "source": [
    "\n",
    "img = test_images[1]\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDFh5yF_CaXW"
   },
   "outputs": [],
   "source": [
    "# Add the image to a batch where it's the only member.\n",
    "img = (np.expand_dims(img,0))\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_rzNSdrCaXY"
   },
   "outputs": [],
   "source": [
    "predictions_single = probability_model.predict(img)\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ai-cpLjO-3A"
   },
   "outputs": [],
   "source": [
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU1Y2OAMCaXb"
   },
   "source": [
    "`keras.Model.predict` возвращает список списков — по одному списку для каждого предсказания в батче. Нам нужны предсказания только для одного изображения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tRmdq_8CaXb"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSXhqsyaZekW"
   },
   "source": [
    "Нейросеть при хорошо подобранных параметрах должна была выдать корректное предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nvj3uNI9ZekY"
   },
   "outputs": [],
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>1. Попробуйте улучшить работу нейронной сети.\n",
    "       Опишите в комментарии к уроку - какого результата вы добились от нейросети? Что помогло вам улучшить ее точность?<br><br>\n",
    "    </li>\n",
    "    \n",
    "    <li>2. Поработайте с документацией TensorFlow 2. Попробуйте найти полезные команды TensorFlow неразобранные на уроке.</li>\n",
    "        \n",
    "    <li>*3. Попробуйте обучить нейронную сеть на TensorFlow 2 на датасете imdb_reviews. Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность? </li>\n",
    "\n",
    "    \n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNwTyMXbZekZ"
   },
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>www.tensorflow.org/api_docs</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPRgZ-YHZeka"
   },
   "source": [
    "## Используемая литература \n",
    "\n",
    "Для подготовки данного методического пособия были использованы следующие ресурсы:\n",
    "<ol>\n",
    "    <li>https://www.tensorflow.org/</li>\n",
    "    <li>https://www.tensorflow.org/tutorials/keras/classification</li>\n",
    "    <li>Singh P., Manure A. - Learn TensorFlow 2.0 - 2020</li>\n",
    "    <li>Шакла Н. — Машинное обучение и TensorFlow 2019</li>\n",
    "    <li>Википедия</li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашнее задание Урок 3. TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем счетчик псевдослучайных чисел\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# загрузим данные imdb\n",
    "\n",
    "NUM_WORDS = 30000\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# загрузим словарь\n",
    "\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fawn', 34701),\n",
       " ('tsukino', 52006),\n",
       " ('nunnery', 52007),\n",
       " ('sonja', 16816),\n",
       " ('vani', 63951),\n",
       " ('woods', 1408),\n",
       " ('spiders', 16115),\n",
       " ('hanging', 2345),\n",
       " ('woody', 2289),\n",
       " ('trawling', 52008)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поменяем ключ-значение в словаре местами\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработаем тренировочные и тестовые данные для подачи в нейросеть\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, maxlen=maxlen)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          480000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 480,289\n",
      "Trainable params: 480,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# создадим нейросеть\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(NUM_WORDS, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 3s 19ms/step - loss: 0.6863 - accuracy: 0.6598\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6193 - accuracy: 0.7909\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4819 - accuracy: 0.8447\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3652 - accuracy: 0.8809\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2949 - accuracy: 0.9004\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2495 - accuracy: 0.9146\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.2173 - accuracy: 0.9252\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.1915 - accuracy: 0.9355\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.1700 - accuracy: 0.9441\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.1516 - accuracy: 0.9525\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.1357 - accuracy: 0.9580\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.1218 - accuracy: 0.9634\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.1095 - accuracy: 0.9680\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0981 - accuracy: 0.9724\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.0890 - accuracy: 0.9757\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.0799 - accuracy: 0.9788\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.0722 - accuracy: 0.9822\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.0647 - accuracy: 0.9847\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0582 - accuracy: 0.9868\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0527 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d0ea97790>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучение нейросети\n",
    "\n",
    "model.fit(train_data,\n",
    "          train_labels,\n",
    "          epochs=20,\n",
    "          batch_size=256,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3564 - accuracy: 0.8762\n",
      "[0.3563753664493561, 0.8761600255966187]\n"
     ]
    }
   ],
   "source": [
    "# результаты на тестовом наборе\n",
    "\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# улучшить точность нейросети помогло уменьшение нейронов в входном слое до 16\n",
    "# также на качество нейросети влияют: кол-во эпох и batch_size\n",
    "# на тестовом наборе данных удалось достичь качества accuracy = 0.876"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
