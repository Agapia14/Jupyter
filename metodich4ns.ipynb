{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgtoaihuY4lX"
   },
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 5. Сверточные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyiI2PFTY4lc"
   },
   "source": [
    "## Содержание методического пособия:\n",
    "\n",
    "\n",
    "<ol>\n",
    "<li>Что такое Сверточные нейронные сети</li>\n",
    "<li>Архитектура Сверточных нейронных сетей</li>\n",
    "<li>Несколько практических примеров сверточных нейронных сетей на Keras</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxM-u0AcY4le"
   },
   "source": [
    "## Что такое Сверточные нейронные сети\n",
    "\n",
    "Сверточные нейронные сети - это нейронные сети приспособленные впервую очередь для задач распознования образов. В их основе лежат работы в области изучения зрительной коры головного мозга. Их отличительная черта - добавление сверточных и пуллинговых слоев в архитектуру нейронной сети. Подробности архитектуры мы рассмотрим в следующей части данного методического пособия, а пока давайте взглянем на области применения данного вида нейронных сетей:\n",
    "\n",
    "- Задачи связанные с определением того какому классу принадлежит объект на фотографии\n",
    "\n",
    "- Сверточные нейронные сети в модифицированном виде могут определять не только что находиться на фотографии, но где находиться (этому виду нейронных сетей будет посвящен отдельный урок)\n",
    "\n",
    "- Распознование лиц. В 2001 г. появился алгоритм Виолы-Джонса, который предложил технологию позволяющую технике находить лица на фотографиях и  в видеопотоке. На данный момент по эфективности этот алгоритм превзайден свертончными нейронными сетями.\n",
    "\n",
    "- Проставление лейблов изображениям. Используется Google, Amazon, Facebook\n",
    "\n",
    "- Визуальный поиск. Используется Google\n",
    "\n",
    "- Рекомендательные системы. Amazon например, использует это для секции \"вам также может понравиться\" для одежды.\n",
    "\n",
    "- В социальных сетях, с помощью них отмечаются люди на фотографиях\n",
    "\n",
    "- Помощь врачам в анализе медицинских снимков\n",
    "\n",
    "- Предиктивная аналитика. Помощь в предсказании проблем со здоровьем\n",
    "\n",
    "- Оценка цифр написанных от руки банками. Одно из самых ранних применений сверточных нейронных сетей.\n",
    "\n",
    "Однако применение сверточных нейронных сетей не ограничивается областью компьютерного зрения. Они также применяются и в других областях:\n",
    "\n",
    "- Анализ текстов. Для этого больше подходят рекуррентные нейронные сети, но когда речь заходит о детекции определенных признаков в тексте например бранной речи, лучше могут подойти сверточные нейронные сети\n",
    "\n",
    "- Предиктивный анализ. В частности предсказание погоды.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Adg0SR5BY4lf"
   },
   "source": [
    "## Глубокое обучение\n",
    "\n",
    "![full_connected.png](attachment:full_connected.png)\n",
    "\n",
    "Источник изображения - https://camo.githubusercontent.com/920e95dc71acebe014549c9288cbf42cbe5c8afc/68747470733a2f2f6861726973686e61726179616e616e2e6f72672f696d616765732f77726974696e672f61727469737469632d7374796c652d7472616e736665722f726570726573656e746174696f6e2d6c6561726e696e672e706e67\n",
    "\n",
    "\n",
    "\n",
    "Глубокое обучение - это обучение глубоких нейронных сетей. Глубокие нейронные сети - это сети с больше чем одним внутренним слоем.\n",
    "\n",
    "Однако, прежде чем мы начнем разбирать глубокое обучение давайте в кратце опишем сверточные нейронные сети. Типичная сверточная нейронная сеть состоит из входного слоя и череды сверточных и пуллинговых слоев, следующих как правило друг за другом и нескольких полносвязных слоев на выходе.\n",
    "\n",
    "Давайте попробуем разобраться в смысле данной архитектуры и как она связана с глубоким обучением. В отношение нейронных сетей известно, что нейронная сеть в один слой может лишить любую задачу. Но такой подход будет очень грубым решением проблемы и вычислительной мощности современных компьютеров не хватит, чтобы нейронная сеть в один слой например могла различать классы объектов на фотографии. \n",
    "\n",
    "Данная диллема решается через другой научный факт известный в отношении нейронных сетей - чем больше слоев тем эффективнее нейросеть. Т.е. строя многослойную нейронную сеть может понадобиться меньше нейронов чем если строить однослойную. Связано это с тем, что каждый слой выучивает признаки на определенном уровне абстракции и следующии за ним слои используют уже имеющиеся признаки, а не выучивают их заново.\n",
    "\n",
    "Давайте в общих чертах посмотрим на то, как происходит процесс обучение в глубокой нейронной сети, поскольку такой же процесс в общих чертах будет характерен и для сверточных нейронных сетей.\n",
    "\n",
    "Допустим мы будем работать с изображениями животных. Первые слои выучат признаки животных низкого уровня абстракции такие как линии под определенными углами, следующие слои на базе этих признаков выучат более сложные признаки, например геом. фигуры на базе сочетания этих линий. Следующие слои выучат такие признаки как глаза, уши и т.д. которые будут составлены из этих геометрических фигур. Подобные высокоасбтрактные признаки как названнные выше уже можно использовать для того чтобы сделать заключение какое животное на картинке.\n",
    "\n",
    "Описанная система лучше с точки зрения вычислительных затрат. Однако если мы сделаем несколько полносвязных слоев где каждый нейрон связан с каждым нейроном другого слоя, то на обсчитывание этих связей уйдет меньше вычисл. ресурсов чем если бы нейронная сеть была в один слой, но всеравно такая нейронная сеть в не учебных задачах будет обучаться неприемлимо долго. \n",
    "\n",
    "\n",
    "## Архитектура Сверточных нейронных сетей\n",
    "\n",
    "![lenet.png](attachment:lenet.png)\n",
    "Источник - http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
    "\n",
    "Сверточные нейронные сети - это самый природо-подобный алгоритм из всех. Современные сверточные нейронные сети базируется на произведшей революцию в комп. зрении нейронной сети AlexNet, она базируется на сверточных нейронных сетях, которые разрабатывал Ян Лекун в 90 гг., те в свою очередь базируется на японском Neocognitron 1980 г., а он свою очередь на открытиях в области зрительной коры головного мозга. Конечно современные архитектуры сверточных нейронных сетей такие Inception-v4 сильно отличаются от сверточных нейронных сетей 90-x. Однако у них есть общие черты, которые и делают сверточные нейронные сети эффективными. Особенности сверточных нейронных сетей о которых речь пойдет далее призваны помочь строить глубокие нейронные сети, имеющими меньшие вычислительные затраты чем полносвязные. \n",
    "\n",
    "Главная отличительная черта сверточных нейронных сетей - это наличие сверточных слоев и пуллинг слоев. Подобные слои как раз и были обнаружены в зрительной коре головного мозга, но они называны по другому и работают конечно более сложным образом. В искусственной нейронной сети сверточный слой состоит из фрагментов, которые связаны только с определенной частью изображения, что позволяет не связывать каждый нейрон с каждым пикселем и уменьшить вычислительные затраты. Конечная цель сверточного слоя получить определенные признаки от изображения и передать их в следующий слой, точно также как и случае с обычной полнозсвязной нейронной сетью. Но сверточный слой это делает более эффективно. Если говорить упрощенно, то сама операция свертки предствляет из себя процесс преобразования большего набора чисел в меньший набор чисел их репрезентующий. Пуллинг слои следуют за сверточными слоями и призваны очистить от лишней информации эти признаки и убрать у них локальную привязку. Сама операция пуллинга если говорить опять же упрощенно представляет из себя процесс отбрасывания менее значимых сигналов представленных в виде чисел. Пулинг слои являются важной состовляющей нейронных сетей, однако из-за них сверточной нейронной сети всеравно где располагаются глаза например у кота над носом или под носом, главное сочетание этих признаков.\n",
    "\n",
    "Сверточная нейронная сеть строиться по принципу пирамиды - первые слои содержат больше нейронов, а последующие все меньше и меньше. Связано это с тем что низкоабстрактных признаков больше чем высокоабстрактных.\n",
    "\n",
    "Как правило на конце нейронной сети располагаются несколько полносвязных слоев. Эти слои как раз уже учатся на высокоабстрактных признаках которых немного и соотвественно не требуется много слоев и соотвесвенно с точки зрения вычислительных затрат они приемлимы. Т.е. получается сверточную нейронную сеть можно условно поделить на две части - одна извлекается признаки, а другая, полносвязная обучается на этих признаках.\n",
    "\n",
    "Однако стоит отметить, что современные сверточные нейронные сети в целях оптимизации их работы снабжаются многим дополнительными архитектурными решениями, такими например как возможность иметь в одном слое разные конфигурации свертки, пропускать при необходимости сигнал обратного распространения ошибки сквозь слои, использование нескольких слоев свертки подряд, неиспользование полносвязных слоев на конце нейронных сетей. Как правило, все эти нововведения направлены на то чтобы сделать нейронные сети более глубокими, что в свою очередь улучшает точность работы нейронных сетей. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBnBxYLnY4lj"
   },
   "source": [
    "## Пример создания сверточных и пуллинг слоев на Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxA2x9MMY4lk",
    "outputId": "f2803db6-46d2-4b9b-cce5-b4b41fdfa9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 1)           10        \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[3.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "\n",
    "# определение входных данных(8 массивов с 8 элементами)\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "\n",
    "# создание модели\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "\n",
    "# вывод описания созданной модели\n",
    "model.summary()\n",
    "\n",
    "# определение дектора вертикальной линии\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "\n",
    "# сохранение весов в модель\n",
    "model.set_weights(weights)\n",
    "\n",
    "# применение фильтра к входным данным\n",
    "yhat = model.predict(data)\n",
    "\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDHFbsi6Y4lo"
   },
   "source": [
    "## Нейронная сеть Lenet5.\n",
    "\n",
    "Lenet5 - это одна из первых сверточных нейронных сетей и она отражает характерные для сверточных нейронных сетей набор элементов - сверточные слои, пуллинг слои и полносвязные слои на конце нейронной сети. Данная архитектура послужила основой для многих современных архитектур сверточных нейронных сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iCA7NxmY4lp",
    "outputId": "0b75cd20-5a49-4eb8-94e0-09ef5259f23a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.7097 - acc: 0.8193 - val_loss: 0.3449 - val_acc: 0.9069\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "Test loss 0.3449, accuracy 90.69%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# загрузка тренировочных и тестовых данных\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# конвертация чисел из uint8 в float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# нормализация данных [0, 1]\n",
    "x_train /= 255 \n",
    "x_test /= 255 \n",
    "\n",
    "# трансформация лейблов в one-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train, 10) \n",
    "y_test = np_utils.to_categorical(y_test, 10) \n",
    "\n",
    "# изменение размерности массива в 4D массив\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28,1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "import keras\n",
    "\n",
    "# инициализация пустой модели\n",
    "model = Sequential()\n",
    "\n",
    "# первый сверточный слой\n",
    "model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "# второй пуллинговый слой\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# третий сверточный слой\n",
    "model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# четвертый пуллинговый слой\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# пятый полносвязный слой\n",
    "model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# сглаживание CNN выхода чтобы можно было его присоединить к полносвязногому слою\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# шестой полносвязный слой\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "\n",
    "# выходной слой с функцией активации softmax\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# компилияция модели\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='SGD', metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "hist = model.fit(x=x_train,y=y_train, epochs=1, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82Mt5ZG-Y4lr"
   },
   "source": [
    "## Пример на Keras более сложной сверточной нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ceurWK4Y4ls"
   },
   "source": [
    "Давайте теперь попробуем сделать несколько усложненный вариант нейронной сети разобранной ранее. В ней будет на несколько слоев больше и в ней будет использоваться data augumentation, процедура позволяющая за счет искажений изображений увеличить количество тренировочных данных, а как мы знаем чем больше тренировочных данных тем лучше будет работать нейросеть. Для обучения нейросети будем использовать датасет cifar-10. В нем 10 категорий объектов, например - лошадь, лягушка, корабль. Данный датасет уже более сложен для нейронных сетей чем mnist, однако он намного проще датасетов наподобие imagenet где используются сотни классов и архитектуры нейронных сетей для подобных датасетов также понадобяться более сложные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nj-zDnfY4ls",
    "outputId": "a5b102e8-7a59-4007-b4e7-ecbf4bf48e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "Epoch 1/1\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.8751 - acc: 0.3107 - val_loss: 1.5636 - val_acc: 0.4304\n",
      "сохранить обученную модель как /home/honeyguide/Desktop/Labour/webinars/neuron_seti_vvedenie/4lesson_cnn/saved_models/keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 134us/step\n",
      "Test loss: 1.5635708665847778\n",
      "Test accuracy: 0.4304\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jrzw9dLDY4lt"
   },
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробовать улучшить точность распознования образов cifar 10 сверточной нейронной сетью, рассмотренной на уроке. Приложить анализ с описанием того, что улучшает работу нейронной сети и что ухудшает.\n",
    "    </li>\n",
    "    <li>Описать также в анализе какие необоходимо внести изменения  в получившуюся у вас нейронную сеть если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwz1T542Y4lu"
   },
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>https://keras.io/layers/convolutional/</li>\n",
    "    <li>https://keras.io/layers/pooling/</li>\n",
    "    <li>https://keras.io/preprocessing/image/</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej-IGPxhY4lu"
   },
   "source": [
    "## Используемая литература \n",
    "\n",
    "Для подготовки данного методического пособия были использованы следующие ресурсы:\n",
    "<ol>\n",
    "    <li>https://keras.io</li>\n",
    "    <li>Шакла Н. — Машинное обучение и TensorFlow 2019</li>\n",
    "    <li>Николенко Сергей Игоревич, Кадурин А. А. - Глубокое обучение. Погружение в мир нейронных сетей  2018</li>\n",
    "    <li>Francois Chollet - Deep Learning with Python 2018</li>\n",
    "    <li>Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton - ImageNet Classification with Deep Convolutional Neural Networks</li>\n",
    "    <li>Karen Simonyan, Andrew Zisserman - Very Deep Convolutional Networks for Large-Scale Image Recognition</li>\n",
    "    <li>Википедия</li>    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vj5_1_tcY4lv"
   },
   "outputs": [],
   "source": [
    "Домашнее задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mqCzXKNfY4lv"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем генератор псевдо случайных чисел\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 36s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Использование data augmentation в реальном времени\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-79db78711db1>:107: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 217s 137ms/step - loss: 1.8419 - accuracy: 0.3232 - val_loss: 1.5278 - val_accuracy: 0.4539\n",
      "сохранить обученную модель как C:\\Users\\user\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "313/313 [==============================] - 9s 30ms/step - loss: 1.5278 - accuracy: 0.4539\n",
      "Test loss: 1.5278273820877075\n",
      "Test accuracy: 0.453900009393692\n"
     ]
    }
   ],
   "source": [
    "# модель из урока\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-9af0a94dea36>:98: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 242s 149ms/step - loss: 1.8840 - accuracy: 0.3040 - val_loss: 1.5963 - val_accuracy: 0.4192\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 214s 136ms/step - loss: 1.6036 - accuracy: 0.4127 - val_loss: 1.4166 - val_accuracy: 0.4826\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 212s 136ms/step - loss: 1.4730 - accuracy: 0.4635 - val_loss: 1.3302 - val_accuracy: 0.5259\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 218s 139ms/step - loss: 1.3851 - accuracy: 0.5019 - val_loss: 1.3030 - val_accuracy: 0.5355\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 230s 147ms/step - loss: 1.3183 - accuracy: 0.5298 - val_loss: 1.3364 - val_accuracy: 0.5467\n",
      "сохранить обученную модель как C:\\Users\\user\\saved_models\\keras_cifar10_trained_model_mod.h5 \n",
      "313/313 [==============================] - 10s 33ms/step - loss: 1.3364 - accuracy: 0.5467\n",
      "Test loss: 1.3364208936691284\n",
      "Test accuracy: 0.5467000007629395\n"
     ]
    }
   ],
   "source": [
    "# попробуем изменить количество эпох\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-d0d8722203cd>:98: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 185s 909ms/step - loss: 2.0970 - accuracy: 0.2181 - val_loss: 1.8676 - val_accuracy: 0.3577\n",
      "сохранить обученную модель как C:\\Users\\user\\saved_models\\keras_cifar10_trained_model_mod.h5 \n",
      "313/313 [==============================] - 10s 32ms/step - loss: 1.8676 - accuracy: 0.3577\n",
      "Test loss: 1.8675814867019653\n",
      "Test accuracy: 0.357699990272522\n"
     ]
    }
   ],
   "source": [
    "# попробуем изменить batch_size\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Не используется data augmentation\n",
      "1563/1563 [==============================] - 220s 135ms/step - loss: 1.8243 - accuracy: 0.3362 - val_loss: 1.5839 - val_accuracy: 0.4215\n",
      "сохранить обученную модель как C:\\Users\\user\\saved_models\\keras_cifar10_trained_model_mod.h5 \n",
      "313/313 [==============================] - 9s 29ms/step - loss: 1.5839 - accuracy: 0.4215\n",
      "Test loss: 1.5839111804962158\n",
      "Test accuracy: 0.42149999737739563\n"
     ]
    }
   ],
   "source": [
    "# отключим data_augmentation\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-2a942cf91a61>:98: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 215s 136ms/step - loss: 1.9375 - accuracy: 0.2754 - val_loss: 1.6511 - val_accuracy: 0.3874\n",
      "сохранить обученную модель как C:\\Users\\user\\saved_models\\keras_cifar10_trained_model_mod.h5 \n",
      "313/313 [==============================] - 9s 30ms/step - loss: 1.6511 - accuracy: 0.3874\n",
      "Test loss: 1.6510666608810425\n",
      "Test accuracy: 0.3874000012874603\n"
     ]
    }
   ],
   "source": [
    "# изменим Dropout\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Не используется data augmentation\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 224s 127ms/step - loss: 1.8328 - accuracy: 0.3274 - val_loss: 1.5393 - val_accuracy: 0.4485\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 188s 120ms/step - loss: 1.5064 - accuracy: 0.4547 - val_loss: 1.3473 - val_accuracy: 0.5247\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 188s 120ms/step - loss: 1.3569 - accuracy: 0.5152 - val_loss: 1.2362 - val_accuracy: 0.5682\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 1.2571 - accuracy: 0.5521 - val_loss: 1.1314 - val_accuracy: 0.5978\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 189s 121ms/step - loss: 1.1734 - accuracy: 0.5863 - val_loss: 1.0873 - val_accuracy: 0.6202\n",
      "сохранить обученную модель как C:\\Users\\user\\saved_models\\keras_cifar10_trained_model_mod.h5 \n",
      "313/313 [==============================] - 9s 27ms/step - loss: 1.0873 - accuracy: 0.6202\n",
      "Test loss: 1.0872632265090942\n",
      "Test accuracy: 0.620199978351593\n"
     ]
    }
   ],
   "source": [
    "# увеличим epochs\n",
    "# отключим data_augmentation\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводы\n",
    "\n",
    "# увеличение кол-ва эпох улучшает качество предсказаний нейронной сети\n",
    "# увеличение параметра batch_size приводит к ухудшению качества работы модели\n",
    "# отключение data_augmentation незначительно увеличивает качество нейросети\n",
    "# увеличение Dropout в сверточных слоях сети до 0.5 приводит к ухудшению качества\n",
    "\n",
    "# одновременное увеличение кол-ва эпох и отключение data_augmentation \n",
    "# позволило значительно улучшить качество работы нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 27s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-45bf2b0f21ec>:107: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 209s 132ms/step - loss: 4.3275 - accuracy: 0.0437 - val_loss: 3.9515 - val_accuracy: 0.1122\n",
      "сохранить обученную модель как C:\\Users\\user\\saved_models\\keras_cifar100_trained_model.h5 \n",
      "313/313 [==============================] - 10s 33ms/step - loss: 3.9515 - accuracy: 0.1122\n",
      "Test loss: 3.95153546333313\n",
      "Test accuracy: 0.11219999939203262\n"
     ]
    }
   ],
   "source": [
    "# построим модель для cifar100, основанную на нейросети из урока\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
    "from keras.datasets import cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 100\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar100_trained_model.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-99 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Не используется data augmentation\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 212s 127ms/step - loss: 4.3058 - accuracy: 0.0479 - val_loss: 3.9608 - val_accuracy: 0.1132\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 186s 119ms/step - loss: 3.8561 - accuracy: 0.1155 - val_loss: 3.5814 - val_accuracy: 0.1748\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 187s 119ms/step - loss: 3.5913 - accuracy: 0.1574 - val_loss: 3.3546 - val_accuracy: 0.2084\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 185s 118ms/step - loss: 3.4042 - accuracy: 0.1908 - val_loss: 3.1858 - val_accuracy: 0.2427\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 185s 119ms/step - loss: 3.2671 - accuracy: 0.2140 - val_loss: 3.0992 - val_accuracy: 0.2526\n",
      "сохранить обученную модель как C:\\Users\\user\\saved_models\\keras_cifar100_trained_model_mod.h5 \n",
      "313/313 [==============================] - 10s 30ms/step - loss: 3.0992 - accuracy: 0.2526\n",
      "Test loss: 3.0992085933685303\n",
      "Test accuracy: 0.2526000142097473\n"
     ]
    }
   ],
   "source": [
    "# попробуем изменить кол-во эпох и отключить data_augmentation\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 100\n",
    "epochs = 5\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar100_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-99 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводы\n",
    "\n",
    "# как и с cifar10, увеличение кол-ва эпох и отключение data_augmentation\n",
    "# привело к улучшению качества работы нейросети с cifar100"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
